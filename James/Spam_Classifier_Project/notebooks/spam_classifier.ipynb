{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631472e3",
   "metadata": {},
   "source": [
    "\n",
    "# Email Spam Classifier (Spambase)\n",
    "This notebook walks through loading the UCI Spambase dataset, preprocessing, training Logistic Regression, SVM, k-NN and Gaussian Naive Bayes, then comparing their performance with accuracy, confusion matrix and ROC curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download dataset (if not present)\n",
    "from src.utils import download_spambase, load_spambase\n",
    "import os\n",
    "DATA_PATH = \"data/spambase.data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    download_spambase(dest=DATA_PATH)\n",
    "else:\n",
    "    print(\"Dataset already present at\", DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11647c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and inspect data\n",
    "names = [f\"feature_{i}\" for i in range(57)] + [\"is_spam\"]\n",
    "df = load_spambase(path=\"data/spambase.data\", names=names)\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811de3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.drop(columns=[\"is_spam\"]).values\n",
    "y = df[\"is_spam\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "print('Train shape', X_train.shape, 'Test shape', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed521d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from src.utils import plot_confusion_matrix, plot_roc\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"GaussianNB\": GaussianNB()\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print('Training', name)\n",
    "    if name in (\"KNN\", \"SVM\", \"LogisticRegression\"):\n",
    "        model.fit(X_train_s, y_train)\n",
    "        y_pred = model.predict(X_test_s)\n",
    "        y_score = model.predict_proba(X_test_s)[:,1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_score = model.predict_proba(X_test)[:,1]\n",
    "        else:\n",
    "            y_score = model.decision_function(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_test, y_score)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    results[name] = {\"accuracy\": acc, \"roc_auc\": roc_auc}\n",
    "    print(f\"{name} -> accuracy: {acc:.4f}, roc_auc: {roc_auc}\")\n",
    "    plot_confusion_matrix(cm, classes=['ham','spam'], out_path=f\"outputs/confusion_{name}.png\")\n",
    "    if roc_auc is not None:\n",
    "        plot_roc(y_test, y_score, out_path=f\"outputs/roc_{name}.png\", model_name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Results summary\n",
    "import json, pprint\n",
    "import os\n",
    "print(\"Outputs saved in ./outputs\")\n",
    "p = \"outputs/results_summary.json\"\n",
    "if os.path.exists(p):\n",
    "    print(\"Found saved summary:\", p)\n",
    "else:\n",
    "    # build a small summary file from in-memory results if available\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "pprint.pprint(results)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
